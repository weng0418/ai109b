# Week13
## 反向傳播算法
* 反向傳播（英語：Backpropagation，縮寫為BP）是「誤差反向傳播」的簡稱，是一種與最優化方法（如梯度下降法）結合使用的，用來訓練人工神經網絡的常見方法。該方法對網絡中所有權重計算損失函數的梯度。這個梯度會反饋給最優化方法，用來更新權值以最小化損失函數。反向傳播要求有對每個輸入值想得到的已知輸出，來計算損失函數梯度。因此，它通常被認為是一種監督式學習方法，雖然它也用在一些無監督網絡（如自動編碼器）中。它是多層前饋網絡的Delt規則的推廣，可以用鏈式法則對每層疊代計算梯度。反向傳播要求人工神經元（或「節點」）的激勵函數可微。

![image](https://user-images.githubusercontent.com/62419535/123519919-996ce100-d6e0-11eb-8a1d-542c6f75e590.png)

# 資料參考:[反向傳播算法](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95)
# 圖片出處:[一分鐘學ＡＩ(3) — 梯度下降與反傳遞算法](https://ccckmit.medium.com/%E4%B8%80%E5%88%86%E9%90%98%E5%AD%B8%EF%BD%81%EF%BD%89-3-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%88%87%E5%8F%8D%E5%82%B3%E9%81%9E%E7%AE%97%E6%B3%95-90f1ed03ffdd)

## PyTorch
* PyTorch是一個開源的Python機器學習庫，基於Torch[，底層由C++實現，應用於人工智慧領域，如自然語言處理。它最初由Facebook的人工智慧研究團隊開發，並且被用於Uber的概率編程軟體Pyro。

* 自動求微分
* ```pip install torch ```
* ```x.norm```: x函數中的變數值相加平方開根號。
* ```torch.tensor```: 單一數據類型元素的多维矩陣。
* ```x.grad```: 該節點的梯度。
* ```f.backward```: 求出函式f的反傳遞。
* ```x.item()```: 從張量x中找出元素值

### PyTorch主要有兩大特徵
* (1)類似於NumPy的張量計算，可使用GPU加速
* (2)基於帶自動微分系統的深度神經網路
