# Week16
## 機器學習
* 在機率理論中，所謂的機率模型，通常是指某種機率獨立性的假設。舉例而言，在簡單貝氏模型 (Naive Bayes Model) 當中，就假設所有的隨機變數 X1, X2,..., Xn 相對於某個前提 C 而言都是條件獨立的，因此可以寫成如下算式。

  ![image](https://user-images.githubusercontent.com/62419535/123521180-b8bb3c80-d6e7-11eb-90d6-a67f6977304c.png)

* 這種機率獨立性的假設，就是一種統計上的假說，我們必須驗證這樣的假說是否合理，如果驗證合理才能使用該公式，否則將會造成龐大的誤差。

![image](https://user-images.githubusercontent.com/62419535/123521060-e5228900-d6e6-11eb-9bb7-34a2e7316119.png)

## 資料來源自老師網站:[機器學習](https://programmermedia.org/root/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E8%AA%B2%E7%A8%8B/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/_doc/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/A-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%B0%A1%E4%BB%8B.md)

## 最大概似估計
* 在統計學中，最大概似估計（Maximum Likelihood Estimation)，也稱極大概似估計，是用來估計一個機率模型的母數的一種方法。

## 蒙地卡羅方法
* 蒙地卡羅方法(Monte Carlo method），也稱統計類比方法，是1940年代中期由於科學技術的發展和電腦的發明，而提出的一種以機率統計理論為指導的數值計算方法。是指使用亂數（或更常見的偽亂數）來解決很多計算問題的方法。
  
  <img src="img/Pi_30K.gif"> 
## 資料來源:[蒙地卡羅方法](https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95)

## 馬可夫鏈
* 「馬可夫鏈」是一種具有狀態的隨機過程，有點像是「有限狀態機」，但是「從目前狀態轉移 s 到下一個狀態 s' 的機率」由![image](https://user-images.githubusercontent.com/62419535/123521637-8a8b2c00-d6ea-11eb-92a6-407a567ed3fc.png)
所表示，這個狀態之轉移機率並不會受到狀態以外的因素所影響，因此與時間無關。

### 馬可夫系統的範例
* 對於一個具有「馬可夫特性」的「機率式有限狀態機」，我們可以用「機率轉移矩陣」進行描述，舉例而言：下圖顯示了一個只有兩個狀態的「馬可夫隨機系統」。
![image](https://user-images.githubusercontent.com/62419535/123521686-b60e1680-d6ea-11eb-8c79-61f5de543ed7.png)

* 若要用機率模型描述上述兩個狀態的馬可夫系統，我們需要給定兩組機率值，第一組是狀態本身的機率 P(s0)、P(s1)。第二組是狀態轉移的機率 Q(s0→s0)、Q(s0→s1)、Q(s1→s0)、Q(s1→s1)。
* 長期來看、馬可夫系統通常最後會達到一個穩定平衡，在平衡的情況之下，每個節點的輸出將會等於該節點的輸入，這就是所謂的「一般平衡條件」。
## 資料來源自老師網站:[馬可夫鏈](https://programmermedia.org/root/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E8%AA%B2%E7%A8%8B/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/_doc/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/B2-%E9%A6%AC%E5%8F%AF%E5%A4%AB%E9%8F%88.md)

## 吉布斯採樣
* 吉布斯採樣（英語：Gibbs sampling）是統計學中用於馬爾科夫蒙特卡洛（MCMC）的一種算法，用於在難以直接採樣時從某一多變量概率分布中近似抽取樣本序列。該序列可用於近似聯合分布、部分變量的邊緣分布或計算積分（如某一變量的期望值）。某些變量可能為已知變量，故對這些變量並不需要採樣。
## 資料來源:[吉布斯採樣](https://zh.wikipedia.org/wiki/%E5%90%89%E5%B8%83%E6%96%AF%E9%87%87%E6%A0%B7)

## 隱藏式馬可夫模型
* 隱藏式馬可夫模型（Hidden Markov Model；縮寫：HMM）或稱作隱性馬可夫模型，是統計模型，它用來描述一個含有隱含未知參數的馬可夫過程。其難點是從可觀察的參數中確定該過程的隱含參數。然後利用這些參數來作進一步的分析，例如圖型識別。
* 在正常的馬可夫模型中，狀態對於觀察者來說是直接可見的。這樣狀態的轉換機率便是全部的參數。而在隱藏式馬可夫模型中，狀態並不是直接可見的，但受狀態影響的某些變數則是可見的。每一個狀態在可能輸出的符號上都有一機率分布。因此輸出符號的序列能夠透露出狀態序列的一些資訊。

![image](https://user-images.githubusercontent.com/62419535/123522446-e4dabb80-d6ef-11eb-8eba-eb477b8848ca.png)

## 資料來源:[隱藏式馬可夫模型](https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B)

## 維特比演算法
* 維特比演算法（英語：Viterbi algorithm）是一種動態規劃演算法。它用於尋找最有可能產生觀測事件序列的維特比路徑——隱含狀態序列，特別是在馬可夫資訊源上下文和隱藏式馬可夫模型中。
* 術語「維特比路徑」和「維特比演算法」也被用於尋找觀察結果最有可能解釋相關的動態規划算法。例如在統計句法分析中動態規划算法可以被用於發現最可能的上下文無關的衍生（解析）的字串，有時被稱為「維特比分析」。

![image](https://user-images.githubusercontent.com/62419535/123522602-ccb76c00-d6f0-11eb-9342-ffae40422f44.png)

## 資料來源:[維特比演算法](https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95) 

## 最大期望算法
* 最大期望演算法（Expectation-maximization algorithm，又譯期望最大化算法）在統計中被用於尋找，依賴於不可觀察的隱性變量的概率模型中，參數的最大似然估計。
* 在統計計算中，最大期望（EM）算法是在概率模型中尋找參數最大似然估計或者最大後驗估計的算法，其中概率模型依賴於無法觀測的隱變量。最大期望算法經常用在機器學習和計算機視覺的數據聚類（Data Clustering）領域。最大期望算法經過兩個步驟交替進行計算，第一步是計算期望（E），利用對隱藏變量的現有估計值，計算其最大似然估計值；第二步是最大化（M），最大化在E步上求得的最大似然值來計算參數的值。M步上找到的參數估計值被用於下一個E步計算中，這個過程不斷交替進行。

## 資料來源:[最大期望算法](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95) 

## K-近鄰演算法
### 在圖型識別領域中，最近鄰居法（KNN演算法，又譯K-近鄰演算法）是一種用於分類和迴歸的無母數統計方法[1]。在這兩種情況下，輸入包含特徵空間（Feature Space）中的k個最接近的訓練樣本。
* 在k-NN分類中，輸出是一個分類族群。一個物件的分類是由其鄰居的「多數表決」確定的，k個最近鄰居（k為正整數，通常較小）中最常見的分類決定了賦予該物件的類別。若k = 1，則該物件的類別直接由最近的一個節點賦予。
* 在k-NN迴歸中，輸出是該物件的屬性值。該值是其k個最近鄰居的值的平均值。

![image](https://user-images.githubusercontent.com/62419535/123522708-9a5a3e80-d6f1-11eb-8564-f5cb0548a4e9.png)

## 資料來源:[K-近鄰演算法](https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95) 

## 決策樹
* 決策樹（Decision tree）由一個決策圖和可能的結果（包括資源成本和風險）組成， 用來創建到達目標的規劃。決策樹建立並用來輔助決策，是一種特殊的樹結構。決策樹是一個利用像樹一樣的圖形或決策模型的決策支持工具，包括隨機事件結果，資源代價和實用性。它是一個算法顯示的方法。決策樹經常在運籌學中使用，特別是在決策分析中，它幫助確定一個能最可能達到目標的策略。如果在實際中，決策不得不在沒有完備知識的情況下被在線採用，一個決策樹應該平行概率模型作為最佳的選擇模型或在線選擇模型算法。決策樹的另一個使用是作為計算條件概率的描述性手段。
### 一個決策樹包含三種類型的節點：
* 決策節點：通常用矩形框來表示
* 機會節點：通常用圓圈來表示
* 終結點：通常用三角形來表示

![image](https://user-images.githubusercontent.com/62419535/123522822-895dfd00-d6f2-11eb-97e9-e4a5f7a8111d.png)
### 決策樹的模型長相:
![image](https://user-images.githubusercontent.com/62419535/123522881-fec9cd80-d6f2-11eb-9b62-8a02bfa7600a.png)

## 資料來源:[決策樹](https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91) 
## 圖片來源:[資料分析&機器學習](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda) 

## 隨機森林
* 在機器學習中，隨機森林是一個包含多個決策樹的分類器，並且其輸出的類別是由個別樹輸出的類別的眾數而定。

![image](https://user-images.githubusercontent.com/62419535/123523114-4735bb00-d6f4-11eb-8137-cf8fe5a2a19e.png)

## 圖片來源:[隨機森林](https://www.twblogs.net/a/5be3a2252b717720b51d9578)
